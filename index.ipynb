{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1572891,"sourceType":"datasetVersion","datasetId":929774}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **The Notebook is under Editing**","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport shutil\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.optimizers import Adam, Adamax, RMSprop\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.applications.xception import decode_predictions\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import f1_score\nfrom cleanlab.filter import find_label_issues\nfrom cleanlab.rank import get_label_quality_scores\nimport keras_cv\nfrom keras_cv.layers import RandAugment\nfrom IPython.display import Image, display\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport tensorflow_probability as tfp\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.losses    import CategoricalFocalCrossentropy\nimport keras\nimport warnings\nimport math\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nimport cv2\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_SIZE = 224","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"len(os.listdir('/kaggle/input/clothing-dataset-full/images_compressed'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(os.listdir('/kaggle/input/clothing-dataset-full/images_original'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/clothing-dataset-full/images.csv')\nlabels.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels.label.value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counts = labels[\"label\"].value_counts()\n\n# Plot\nplt.figure(figsize=(12, 6))\nlabel_counts.plot(kind=\"bar\")\n\nplt.xlabel(\"Garment Class\")\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\n\n# Save to file\nplt.savefig(\"label_distribution.png\", dpi=300)\n\n# Optionally show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Suppose 'labels' is your DataFrame with two columns: \n#   - 'image' (e.g. \"000123\" or \"IMG_0456\") \n#   - 'label' (the original class name, e.g. \"T-Shirt\", \"Skip\", \"Blouse\", etc.)\n\n# 1) Drop the rows whose label is exactly \"Skip\", \"Not sure\", or \"Other\"\ndrop_these = [\"Skip\", \"Not sure\", \"Other\"]\nlabels = labels[~labels[\"label\"].isin(drop_these)].copy()\n\n# 2) Define a mapping for all classes that need merging into a parent class\n#    a) Everything in {\"Blouse\",\"Polo\",\"Undershirt\",\"Top\",\"Body\"} → \"Shirt\"\n#    b) Everything in {\"Blazer\",\"Hoodie\"}                 → \"Outwear\"\n#    c) Leave the remaining labels unchanged\nmerge_map = {\n    \"Top\":        \"Basic Top\",\n    \"Undershirt\": \"Basic Top\",\n    \"Body\":       \"Basic Top\",\n    \"Polo\":       \"Shirt\",\n    \"Blouse\":     \"Shirt\",\n    \"Blazer\":     \"Outwear\",\n    \"Hoodie\":     \"Outwear\"\n}\n\n# 3) Apply the mapping: if a label appears in merge_map, replace it; otherwise keep it\nlabels[\"label\"] = labels[\"label\"].replace(merge_map)\n\n# 4) Add the “.jpg” extension to the image filename (so that it matches the files on disk)\nlabels[\"image\"] = labels[\"image\"] + \".jpg\"\n\n# 5) (Optional) Recompute and display the new, cleaned class counts to verify the unbalance\nnew_counts = labels[\"label\"].value_counts()\nprint(new_counts)\n\nlabels.to_csv(\"/kaggle/working/cleaned_labels.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_counts = labels[\"label\"].value_counts()\n\n# Plot\nplt.figure(figsize=(12, 6))\nlabel_counts.plot(kind=\"bar\")\n\nplt.xlabel(\"Garment Class\")\nplt.ylabel(\"Number of Images\")\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\n\n# Save to file\nplt.savefig(\"label_distribution.png\", dpi=300)\n\n# Optionally show the plot\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_lst = labels.label.unique().tolist()\nlabels_lst","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Splitting the dataset","metadata":{}},{"cell_type":"code","source":"\n\ntrain_df, test_df = train_test_split(labels, test_size=0.1, random_state=42, stratify=labels['label'])\ntrain_df, val_df = train_test_split(train_df, test_size=0.11111111, random_state=42, stratify=train_df['label'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    parent_dir = '/kaggle/working/clothes'\n    os.mkdir(parent_dir)\n\n    for split in ['training', 'validation', 'testing']:\n        path = os.path.join(parent_dir , split)\n        os.mkdir(path)\n        for label  in labels_lst:\n            n_path = os.path.join(path , label)\n            os.mkdir(n_path)\nexcept OSError:\n    print('Existing Directories')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"not_found_images = []\n\ndef copy_files(file_df, split, source_dir, destination_dir):\n    global not_found_images\n    for _, row in file_df.iterrows():\n        img_name = row['image']\n        label = row['label']\n        \n        # Define source and destination paths\n        src = os.path.join(source_dir, img_name)\n        dst = os.path.join(destination_dir, split, label, img_name)\n        \n        try:\n            # Copy the file\n            shutil.copy2(src, dst)\n        except FileNotFoundError:\n            not_found_images.append(src)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"source_dir = '/kaggle/input/clothing-dataset-full/images_compressed'\ndestination_dir = '/kaggle/working/clothes'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Copy images to the appropriate directories\ncopy_files(train_df, 'training', source_dir, destination_dir)\ncopy_files(val_df, 'validation', source_dir, destination_dir)\ncopy_files(test_df, 'testing', source_dir, destination_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(not_found_images) # No images not found","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Display Sample images","metadata":{}},{"cell_type":"code","source":"# Display Sample image\n\ndef display_sample_image(split, label):\n    images = os.listdir(os.path.join(destination_dir, split, label))\n    img = random.choice(images)\n    return load_img(os.path.join(destination_dir, split, label, img), target_size=(IMAGE_SIZE, IMAGE_SIZE))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_sample_image('training', 'Outwear')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display Sample images\n\ndef display_sample_images(split, label):\n    for i in range(5):\n        plt.subplot(1, 5, i+1)\n        plt.imshow(display_sample_image(split, label))\n        plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for label in labels_lst:\n    print(label)\n    display_sample_images('training', label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the number of images in each directory\ndef check_no_images(label):\n    print(f'{label} Total Images:', labels[labels.label == label].shape[0])\n    print(f'{label} Training Images:', len(os.listdir(os.path.join(destination_dir, 'training', label))))\n    print(f'{label} Validation Images:', len(os.listdir(os.path.join(destination_dir, 'validation', label))))\n    print(f'{label} Testing Images:', len(os.listdir(os.path.join(destination_dir, 'testing', label))))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"check_no_images('T-Shirt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"check_no_images('Shoes')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/working/clothes\"\n\n# 2) Sub‐directories for train/val/test\nTRAIN_DIR = f\"{DATA_ROOT}/training\"\nVAL_DIR   = f\"{DATA_ROOT}/validation\"\nTEST_DIR  = f\"{DATA_ROOT}/testing\"\n\n# 3) Image dimensions and batch size\nIMG_HEIGHT = 224\nIMG_WIDTH  = 224\nBATCH_SIZE = 32\n\n# 4) Mean/STD normalization (ImageNet‐style) or simply rescale [0,255] → [0,1]\n#    (Keras’ built-in Rescaling layer or rescale=1./255 in ImageDataGenerator)\nRESCALE_FACTOR = 1.0 / 255.0\n\n# 5) Augmentation parameters for the training generator\nTRAIN_AUG_PARAMS = dict(\n    rescale=RESCALE_FACTOR,\n    rotation_range=15,          # randomly rotate by up to ±15°\n    width_shift_range=0.10,     # randomly shift horizontally by ±10%\n    height_shift_range=0.10,    # randomly shift vertically by ±10%\n    shear_range=0.10,           # shear transformations\n    zoom_range=0.10,            # randomly zoom in/out by ±10%\n    horizontal_flip=True,       # randomly flip images left→right\n    fill_mode=\"nearest\"         # filling strategy for newly created pixels\n)\n\n# 6) For validation & test, we typically only rescale (no random aug)\nVAL_TEST_PARAMS = dict(\n    rescale=RESCALE_FACTOR\n)\n\n\n# ──────────────────────────────────────────────────────────────────────────────\n# STEP A: CREATE KERAS IMAGE DATA GENERATORS\n# ──────────────────────────────────────────────────────────────────────────────\n\ntrain_datagen = ImageDataGenerator(**TRAIN_AUG_PARAMS)\nval_datagen   = ImageDataGenerator(**VAL_TEST_PARAMS)\ntest_datagen  = ImageDataGenerator(**VAL_TEST_PARAMS)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# STEP B: POINT EACH GENERATOR AT THE CORRECT FOLDER\n# ──────────────────────────────────────────────────────────────────────────────\n\n#  B.1) Training generator:\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",    # since you have multiple classes (one‐hot)\n    shuffle=True,\n    seed=42\n)\n\n#  B.2) Validation generator:\nval_generator = val_datagen.flow_from_directory(\n    VAL_DIR,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    shuffle=False,               # keep deterministic ordering for validation metrics\n    seed=42\n)\n\n#  B.3) Test generator:\n#       Use shuffle=False so that predictions ↔ filenames stay aligned\ntest_generator = test_datagen.flow_from_directory(\n    TEST_DIR,\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    shuffle=False,\n    seed=42\n)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# STEP C: (OPTIONAL) DISPLAY A BATCH OF TRAIN IMAGES TO VERIFY AUGMENTATIONS\n# ──────────────────────────────────────────────────────────────────────────────\n\n\n\n# Grab one batch from train_generator\nimages_batch, labels_batch = next(train_generator)\n\n# Show a 3×3 grid of random images + their one‐hot labels\nplt.figure(figsize=(8, 8))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images_batch[i])\n    label_index = labels_batch[i].argmax()   # integer index of the class\n    label_name  = list(train_generator.class_indices.keys())[label_index]\n    plt.title(label_name, fontsize=8)\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_no_images = train_generator.n + valid_generator.n + test_generator.n\nprint('Training Images:', round(train_generator.n / total_no_images *100, 2), '%')\nprint('Validation Images:', round(valid_generator.n / total_no_images *100, 2), '%')\nprint('Testing Images:', round(test_generator.n / total_no_images *100, 2), '%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the total number of images \nassert len(labels) == total_no_images, 'Total number of images does not match'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n    MaxPooling2D(2,2),\n\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(train_generator.num_classes, activation='softmax')\n])\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CHECKPOINT_PATH = \"/kaggle/working/base_model.weights.h5\"\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=CHECKPOINT_PATH,\n    monitor=\"val_loss\",   # if you have defined a custom 'macro_f1' metric, otherwise use \"val_loss\" or \"val_categorical_accuracy\"\n    save_best_only=True,\n    mode=\"min\",               # we want to maximize macro‐F1; use \"min\" if monitoring \"val_loss\"\n    verbose=1,\n    save_weights_only=True\n)\n\nearlystop_cb = EarlyStopping(\n    monitor=\"val_loss\",   # again, or \"val_loss\"\n    mode=\"min\",               # or \"min\" for loss\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-3),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_generator,\n    epochs=30,\n    validation_data=val_generator,\n    callbacks=[checkpoint_cb, earlystop_cb]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# To get per‐image predictions (for confusion matrix / macro‐F1), do:\n\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 1","metadata":{}},{"cell_type":"code","source":"\n\n#  E.1) Build the model:\nbase_model = EfficientNetB0(\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n    include_top=False,\n    weights=\"imagenet\"\n)\nbase_model.trainable = False   # freeze the backbone for Phase 1\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutputs = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=outputs)\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CHECKPOINT_PATH = \"/kaggle/working/best_base_model.weights.h5\"\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=CHECKPOINT_PATH,\n    monitor=\"val_loss\",   # if you have defined a custom 'macro_f1' metric, otherwise use \"val_loss\" or \"val_categorical_accuracy\"\n    save_best_only=True,\n    mode=\"min\",               # we want to maximize macro‐F1; use \"min\" if monitoring \"val_loss\"\n    verbose=1,\n    save_weights_only=True\n)\n\nearlystop_cb = EarlyStopping(\n    monitor=\"val_loss\",   # again, or \"val_loss\"\n    mode=\"min\",               # or \"min\" for loss\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\n#  E.2) Fit for a few epochs (just to demonstrate that the generators hook up correctly):\nhistory = model.fit(\n    train_generator,\n    epochs=30,              # set a large upper limit; EarlyStopping will trim it down\n    validation_data=val_generator,\n    callbacks=[checkpoint_cb, earlystop_cb],\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# To get per‐image predictions (for confusion matrix / macro‐F1), do:\n\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  E.1) Build the model:\nbase_model = Xception(\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n    include_top=False,\n    weights=\"imagenet\"\n)\nbase_model.trainable = False   # freeze the backbone for Phase 1\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.3)(x)\noutputs = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=outputs)\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-3),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CHECKPOINT_PATH = \"/kaggle/working/best_base_X_model.weights.h5\"\n\ncheckpoint_cb = ModelCheckpoint(\n    filepath=CHECKPOINT_PATH,\n    monitor=\"val_loss\",   # if you have defined a custom 'macro_f1' metric, otherwise use \"val_loss\" or \"val_categorical_accuracy\"\n    save_best_only=True,\n    mode=\"min\",               # we want to maximize macro‐F1; use \"min\" if monitoring \"val_loss\"\n    verbose=1,\n    save_weights_only=True\n)\n\nearlystop_cb = EarlyStopping(\n    monitor=\"val_loss\",   # again, or \"val_loss\"\n    mode=\"min\",               # or \"min\" for loss\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\n#  E.2) Fit for a few epochs (just to demonstrate that the generators hook up correctly):\nhistory = model.fit(\n    train_generator,\n    epochs=50,              # set a large upper limit; EarlyStopping will trim it down\n    validation_data=val_generator,\n    callbacks=[checkpoint_cb, earlystop_cb],\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_random_seeds(seed: int):\n    \"\"\"Sets Python, NumPy, and TensorFlow random seeds for reproducibility.\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n\ndef build_frozen_xception_model(num_classes: int, dropout_rate: float = 0.3):\n    \"\"\"\n    Constructs an Xception-based model with a frozen convolutional stem,\n    returning a compiled Keras model ready for training.\n    \"\"\"\n    base = Xception(\n        weights=\"imagenet\",\n        include_top=False,\n        input_shape=(224, 224, 3),\n    )\n    base.trainable = False  # freeze the ImageNet‐pretrained stem\n\n    x = base.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(dropout_rate)(x)\n    outputs = Dense(num_classes, activation=\"softmax\")(x)\n\n    model = Model(inputs=base.input, outputs=outputs)\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef compute_macro_f1_on_generator(model, generator):\n    \"\"\"\n    Runs model.predict(...) on `generator` (entire dataset),\n    then computes macro-F1 using sklearn.\n    Returns a single float.\n    \"\"\"\n    # 1) Reset the generator so it starts from the first batch\n    generator.reset()\n    steps = int(np.ceil(generator.samples / generator.batch_size))\n\n    # 2) Get predicted class indices\n    pred_probs = model.predict(generator, steps=steps, verbose=0)\n    pred_labels = np.argmax(pred_probs, axis=1)\n\n    # 3) True labels in the same order\n    true_labels = generator.classes\n\n    # 4) Compute macro-F1 (with labels in [0..num_classes-1])\n    macro_f1 = f1_score(true_labels, pred_labels, average=\"macro\")\n    return macro_f1\n\ndef train_frozen_xception(seed: int):\n    \"\"\"\n    Trains a frozen‐stem Xception head on train_generator / val_generator\n    using the given random seed. Returns the best validation macro‐F1.\n    \"\"\"\n    # 1) Set all random seeds so that shuffling, weight inits, etc. are reproducible:\n    set_random_seeds(seed)\n\n    # 2) Rebuild data generators so that their internal shuffles also use the seed:\n    #    (Only necessary if your generators were created without a fixed seed.)\n    #    If you originally did: \n    #         train_generator = train_datagen.flow_from_directory(..., shuffle=True, seed=42)\n    #    then re‐instantiating with `seed=seed` ensures each run shuffles differently.\n    train_generator.seed = seed\n    val_generator.seed = seed\n\n    # 3) Build & compile the model\n    model = build_frozen_xception_model(num_classes=train_generator.num_classes)\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n\n    ckpt_path = f\"/kaggle/working/xception_seed{seed}_best.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        save_best_only=True,\n        save_weights_only=True,\n        mode=\"min\",\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    )\n    \n    model.fit(\n        train_generator,\n        epochs=50,                    # upper‐bound on epochs\n        validation_data=val_generator,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1\n    )\n\n    val_macro_f1 = compute_macro_f1_on_generator(model, val_generator)\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nf1_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Running seed {seed} ===\")\n    f1 = train_frozen_xception(seed)\n    print(f\"Seed {seed} → val macro-F1 = {f1:.4f}\\n\")\n    f1_scores.append(f1)\n\nf1_scores = np.array(f1_scores)\nmean_f1 = f1_scores.mean()\nstd_f1  = f1_scores.std()\n\nprint(f\"\\nFinal frozen-Xception val macro-F1 over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 2","metadata":{}},{"cell_type":"code","source":"\nCLEAN_TRAIN_ROOT = \"/kaggle/working/clean_train\"\n\nos.makedirs(CLEAN_TRAIN_ROOT, exist_ok=True)\n\nfor cls in labels_lst:\n    class_dir = os.path.join(CLEAN_TRAIN_ROOT, cls)\n    os.makedirs(class_dir, exist_ok=True)\n\nnot_found = []\n\nfor idx, row in labels.iterrows():\n    filename = row[\"image\"]   # e.g. \"img_1234.jpg\"\n    label    = row[\"label\"]   # e.g. \"T-Shirt\"\n    \n    # Build source and destination paths\n    src = os.path.join(source_dir, filename)\n    dst = os.path.join(CLEAN_TRAIN_ROOT, label, filename)\n    \n    try:\n        shutil.copy2(src, dst)\n    except FileNotFoundError:\n        # In case some filenames are missing from SOURCE_DIR\n        not_found.append(src)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# 1a) Create an ImageDataGenerator that ONLY rescales:\ntrain_datagen_cl = ImageDataGenerator(rescale=1.0/255.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator_cl = train_datagen_cl.flow_from_directory(\n    CLEAN_TRAIN_ROOT,\n    target_size=(224, 224),       # Resize every image to 224×224\n    color_mode=\"rgb\",             # 3‐channel RGB (as Xception expects)\n    batch_size=32,                # You can adjust batch_size if you like\n    class_mode=\"categorical\",     # We have 10 one‐hot classes in subfolders\n    shuffle=False                 # IMPORTANT: keep a fixed order for CleanLab\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_CLASSES = train_generator_cl.num_classes  # should be 10\nfrozen_xcep = build_frozen_xception_model(num_classes=NUM_CLASSES)\nfrozen_xcep.load_weights(\"/kaggle/working/xception_seed42_best.weights.h5\")\n\ntrain_generator_cl.reset()\nsteps_train = int(np.ceil(train_generator_cl.samples / train_generator_cl.batch_size))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"probabilities = frozen_xcep.predict(train_generator_cl, steps=steps_train, verbose=1)\n\ntrue_labels = train_generator_cl.classes  # shape: (N_train,)\nfilepaths = train_generator_cl.filepaths   # list of length N_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# 5a) Identify all indices whose “label vs. predicted probs” look suspicious\nlabel_issues_mask = find_label_issues(\n    labels=true_labels,\n    pred_probs=probabilities,\n    return_indices_ranked_by=\"normalized_margin\"\n)\nproblem_indices = np.where(label_issues_mask)[0]\nprint(\"Number of flagged images:\", len(problem_indices))\n\n# 5b) If you only want the top‐K worst examples to inspect manually:\nK = 50\ntopk_problem_indices = problem_indices[:K]\nprint(\"Top‐K flagged indices:\", topk_problem_indices[:10])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"true_labels = train_generator_cl.classes  # shape: (N_train,)\npred_probs = probabilities                # shape: (N_train, 10)\n\n# 5.1) Find likely mislabeled examples (boolean mask of length N_train)\nlabel_issues_mask = find_label_issues(\n    labels=true_labels,\n    pred_probs=pred_probs,\n    return_indices_ranked_by=\"normalized_margin\"\n)\n\n# 5.2) Get the indices of all examples flagged as potential issues, ordered by severity\nproblem_indices = np.where(label_issues_mask)[0]\nlen(problem_indices), \"images flagged as potential label issues\"\n\n# 5.3) (Optional) If you only want the top-K worst images to inspect:\nK = 50\ntopk_problem_indices = problem_indices[:K]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build a reverse‐map from class index → class name (string)\nidx_to_class = {v: k for k, v in train_generator_cl.class_indices.items()}\n\n# Inspect the top K flagged images\nfor idx in topk_problem_indices:\n    img_path = train_generator_cl.filepaths[idx]\n    actual_class_idx = true_labels[idx]\n    predicted_class_idx = np.argmax(pred_probs[idx])\n    \n    actual_name    = idx_to_class[actual_class_idx]\n    predicted_name = idx_to_class[predicted_class_idx]\n\n    print(f\"Index {idx}  |  File: {os.path.basename(img_path)}\")\n    print(f\"  → Current label = '{actual_name}'\")\n    print(f\"  → Model predicts = '{predicted_name}'\")\n    display(Image(filename=img_path, width=200))\n    print(\"──\" * 20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(problem_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 2B","metadata":{}},{"cell_type":"code","source":"rand_augment_layer = RandAugment(\n    value_range=(0, 255),\n    augmentations_per_image=2,\n    magnitude=0.3,              # moderately strong augmentations\n    magnitude_stddev=0.1,       # mild randomness in strength\n    rate=0.7                    # apply to 70% of images\n)\n\n# Full augmentation pipeline: flip + rotate + RandAugment + clip + rescale\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.10),                 # ±10% rotation\n    rand_augment_layer,                                   # RandAugment with 70% rate\n    tf.keras.layers.Lambda(lambda x: tf.clip_by_value(x, 0, 255)),  # clip values just in case\n    tf.keras.layers.Rescaling(1.0 / 255.0)                # normalize to [0,1]\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ──────────────────────────────────────────────────────────────────────────────\n# 3.A) Training dataset with RandAugment-Lite\n# ──────────────────────────────────────────────────────────────────────────────\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/working/clothes/training\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n    image_size=(224, 224),\n    batch_size=32,\n    shuffle=True  # we will re‐shuffle each seed below\n)\n\nclass_names = train_ds.class_names\nnum_classes = len(class_names)\n\ndef apply_randaug(image, label):\n    # `image` comes in as uint8 in [0,255]; feed directly into data_augmentation\n    image = data_augmentation(image)  # flip, ±10% rotation, 2 random ops, clip, rescale\n    return image, label\n\ntrain_ds = train_ds.map(apply_randaug, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# 3.B) Validation dataset (only rescale)\n# ──────────────────────────────────────────────────────────────────────────────\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/working/clothes/validation\",\n    labels=\"inferred\",\n    label_mode=\"categorical\",\n    image_size=(224, 224),\n    batch_size=32,\n    shuffle=False\n)\n\nval_ds = val_ds.map(\n    lambda x, y: (tf.cast(x, tf.float32) / 255.0, y),\n    num_parallel_calls=tf.data.AUTOTUNE\n)\nval_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_randaug(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Re‐shuffle the training dataset each seed to get a different batch order\n    train_shuffled = train_ds.shuffle(buffer_size=2000, seed=seed)\n\n    # 2) Build a fresh frozen‐Xception model\n    model = build_frozen_xception_model(num_classes)\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    # 3) Set up callbacks: monitor val_loss, save best weights only\n    ckpt_path = f\"/kaggle/working/randaug_xcep_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=7,\n        restore_best_weights=True,\n        verbose=1\n    )\n\n    # 4) Fit for up to 50 epochs\n    history = model.fit(\n        train_shuffled,\n        validation_data=val_ds,\n        epochs=50,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1\n    )\n\n    # 5) Load the best‐saved weights and compute validation macro‐F₁\n    model.load_weights(ckpt_path)\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"Seed {seed} → val macro-F₁ (RandAugment) = {val_macro_f1:.4f}\")\n    return val_macro_f1\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nrandaug_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Training with RandAugment-Lite (seed {seed}) ===\")\n    f1 = train_with_randaug(seed)\n    randaug_scores.append(f1)\n\nmean_f1 = np.mean(randaug_scores)\nstd_f1  = np.std(randaug_scores)\nprint(f\"\\n→ RandAugment frozen-Xception val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/randaug_xcep_seed42.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 2C","metadata":{}},{"cell_type":"code","source":"def mixup_batch(images, labels, alpha=0.2):\n    \"\"\"\n    images : float32 in [0,1], shape (B,H,W,C)\n    labels : one-hot float32,   shape (B,num_classes)\n    \"\"\"\n    batch_size = tf.shape(images)[0]\n\n    # 1) λ ~ Beta(α, α)  →  shape (B,1,1,1)\n    lam = tfp.distributions.Beta(alpha, alpha).sample([batch_size, 1, 1, 1])\n    lam_lbl = tf.reshape(lam, [batch_size, 1])              # shape (B,1) for labels\n\n    # 2) Shuffle within the batch\n    idx = tf.random.shuffle(tf.range(batch_size))\n    img2   = tf.gather(images, idx)\n    label2 = tf.gather(labels, idx)\n\n    # 3) Mix\n    mixed_images = lam * images + (1.0 - lam) * img2\n    mixed_labels = lam_lbl * labels + (1.0 - lam_lbl) * label2\n    return mixed_images, mixed_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_mixup(image_batch, label_batch):\n    # image_batch: (B,224,224,3) in [0,1], label_batch: (B,10) one-hot\n    return mixup_batch(image_batch, label_batch, alpha=0.2)\n\ntrain_ds_mix = train_ds.map(apply_mixup, num_parallel_calls=tf.data.AUTOTUNE)\ntrain_ds_mix = train_ds_mix.prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_randaug_mixup(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Shuffle & augment (RandAugment + MixUp)\n    # train_shuffled = train_generator_with_mixup.shuffle(buffer_size=2000, seed=seed)\n    # train_shuffled = train_shuffled.map(apply_mixup, num_parallel_calls=tf.data.AUTOTUNE)\n    # train_shuffled = train_shuffled.prefetch(tf.data.AUTOTUNE)\n\n    # 2) Build & compile model\n    model = build_frozen_xception_model(num_classes)\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    # 3) Callbacks (monitor val_loss)\n    ckpt_path = f\"/kaggle/working/randaug_mixup_xcep_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    )\n    # print(len(train_generator))\n    # 4) Fit (50 epochs max)\n    model.fit(\n        train_generator_with_mixup,\n        steps_per_epoch=len(train_generator),\n        validation_data=val_generator,\n        validation_steps=(val_generator.samples // val_generator.batch_size),\n        epochs=50,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1\n    )\n\n    # 5) Load best weights & compute val macro‐F₁\n    model.load_weights(ckpt_path)\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"Seed {seed} → val macro-F₁ (RandAugment + MixUp) = {val_macro_f1:.4f}\")\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nmixup_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Training with RandAugment + MixUp (seed {seed}) ===\")\n    score = train_with_randaug_mixup(seed)\n    mixup_scores.append(score)\n\nmean_score = np.mean(mixup_scores)\nstd_score  = np.std(mixup_scores)\nprint(f\"\\n→ RandAugment + MixUp frozen‐Xception val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_score:.4f} ± {std_score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/randaug_mixup_xcep_seed42.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 2D","metadata":{}},{"cell_type":"code","source":"class_names = sorted(train_df[\"label\"].unique())  # same ordering as your data folders\nclass_to_idx = {cls: i for i, cls in enumerate(class_names)}\n\n# 2. Convert labels to integer indices\nlabel_indices = train_df[\"label\"].map(class_to_idx).values\n\n# 3. Compute balanced weights\nweights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.arange(len(class_names)),\n    y=label_indices\n)\n\n# 4. Wrap as dict for Keras\nclass_weights = dict(enumerate(weights))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_with_randaug(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Re‐shuffle the training dataset each seed to get a different batch order\n    train_shuffled = train_ds.shuffle(buffer_size=2000, seed=seed)\n\n    # 2) Build a fresh frozen‐Xception model\n    model = build_frozen_xception_model(num_classes)\n\n    model.compile(\n        optimizer=Adam(learning_rate=1e-3),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    # 3) Set up callbacks: monitor val_loss, save best weights only\n    ckpt_path = f\"/kaggle/working/randaug_xcep_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=7,\n        restore_best_weights=True,\n        verbose=1\n    )\n\n    # 4) Fit for up to 50 epochs\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=50,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1,\n        class_weight=class_weights\n    )\n\n    # 5) Load the best‐saved weights and compute validation macro‐F₁\n    model.load_weights(ckpt_path)\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"Seed {seed} → val macro-F₁ (RandAugment) = {val_macro_f1:.4f}\")\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nrandaug_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Training with RandAugment-Lite (seed {seed}) ===\")\n    f1 = train_with_randaug(seed)\n    randaug_scores.append(f1)\n\nmean_f1 = np.mean(randaug_scores)\nstd_f1  = np.std(randaug_scores)\nprint(f\"\\n→ RandAugment frozen-Xception val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/randaug_xcep_seed2022.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/randaug_mixup_xcep_seed42.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 3","metadata":{}},{"cell_type":"code","source":"\ndef build_and_unfreeze_xception(\n    n_unfreeze: int = 20,\n):\n    \"\"\"\n    1. Build Xception+head.\n    2. Load those weights (frozen-head).\n    3. Unfreeze the top `n_unfreeze` layers of the Xception base.\n    4. Recompile with lr_backbone for all trainable layers.\n    \"\"\"\n    # 1) Build fresh model with pre-trained ImageNet base (all frozen by default)\n    \n    base = Xception(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n    x = GlobalAveragePooling2D()(base.output)\n    x = Dropout(0.3)(x)\n    output = Dense(num_classes, activation=\"softmax\")(x)\n    model = Model(inputs=base.input, outputs=output)\n\n    # 2) If you have frozen-head weights from Phase 2-D, load them now\n    model.load_weights(\"/kaggle/working/randaug_xcep_seed2022.weights.h5\")\n\n    # 3) Selectively unfreeze: only the last `n_unfreeze` layers of the base\n    #    (we assume base is model.layers[1] if you built with `base = Xception...`)\n    base.trainable = True\n    # Count base layers and mark the first (len(base.layers) - n_unfreeze) as frozen\n    for layer in base.layers[:-n_unfreeze]:\n        layer.trainable = False\n    for layer in base.layers[-n_unfreeze:]:\n        layer.trainable = True\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_phase3a(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Shuffle the training dataset so that each seed sees a different batch order\n    train_shuffled = train_ds.shuffle(buffer_size=2000, seed=seed)\n\n    # 2) Build & unfreeze the top‐20 layers, loading Phase 2-D weights\n    model = build_and_unfreeze_xception(\n        n_unfreeze=20\n    )\n\n    optimizer = Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer,\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    # 3) Set up callbacks: monitor val_loss, save best weights only\n    ckpt_path = f\"/kaggle/working/fine_tuned_xcep_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=7,\n        restore_best_weights=True,\n        verbose=1\n    )\n\n    # 4) Fit for up to 30 epochs, passing class_weights\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=50,\n        class_weight=class_weights,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1\n    )\n\n    # 5) Load best‐saved weights and compute validation macro-F₁\n    model.load_weights(ckpt_path)\n\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"\\nSeed {seed} → Phase 3-A val macro-F₁ = {val_macro_f1:.4f}\\n\")\n    return val_macro_f1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nphase3a_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Phase 3-A, training with seed {seed} ===\")\n    f1 = train_phase3a(seed)\n    phase3a_scores.append(f1)\n\nmean_f1 = np.mean(phase3a_scores)\nstd_f1  = np.std(phase3a_scores)\nprint(f\"\\n→ Phase 3-A (Unfreeze top 20) val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/fine_tuned_xcep_seed2022.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 3B","metadata":{}},{"cell_type":"code","source":"def train_phase3c(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Shuffle the training dataset each seed\n    # train_shuffled = train_ds.shuffle(buffer_size=2000, seed=seed)\n\n    # 2) Build & unfreeze top 20 layers, load Phase 2-D weights\n    model = build_and_unfreeze_xception(\n        n_unfreeze = 20,  \n\n    )\n\n    # 3) Compile with Focal Loss (γ = 2.0, no label smoothing)\n    focal_loss = CategoricalFocalCrossentropy(\n        gamma=2.0,\n        alpha=0.2,\n        label_smoothing=0.0,   # ensure soft labels come only from RandAugMix, not smoothing\n        from_logits=False\n    )\n    optimizer = Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss,\n        metrics=[\"accuracy\"]\n    )\n\n    # 4) Callbacks: monitor val_loss, save best weights\n    ckpt_path = f\"/kaggle/working/fine_tuned_xcep_focal_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath=ckpt_path,\n        monitor=\"val_loss\",\n        mode=\"min\",\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"min\",\n        patience=4,\n        restore_best_weights=True,\n        verbose=1\n    )\n\n    # 5) Fit up to 30 epochs (RandAugment + Focal Loss, no class weights)\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=50,\n        callbacks=[checkpoint_cb, earlystop_cb],\n        verbose=1\n    )\n\n    # 6) Load best weights & compute validation macro-F₁\n    model.load_weights(ckpt_path)\n\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"\\nSeed {seed} → Phase 3-C val macro-F₁ = {val_macro_f1:.4f}\\n\")\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nphase3c_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Phase 3-C (Focal Loss), training with seed {seed} ===\")\n    score = train_phase3c(seed)\n    phase3c_scores.append(score)\n\nmean_f1 = np.mean(phase3c_scores)\nstd_f1  = np.std(phase3c_scores)\nprint(f\"\\n→ Phase 3-C (Focal Loss) val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/fine_tuned_xcep_focal_seed2022.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 3D","metadata":{}},{"cell_type":"code","source":"# 1) Extract the sorted list of unique labels from train_df\nunique_labels = sorted(train_df[\"label\"].unique())\n# Example: [\"Basic Top\", \"Dress\", \"Hat\", \"Longsleeve\", …, \"T-Shirt\"]\n\n# 2) Build a mapping from each string‐label → integer index\n#    (0, 1, 2, …) in exactly the same order as `unique_labels`.\nlabel_to_index = {lbl: idx for idx, lbl in enumerate(unique_labels)}\n\n# 3) Allocate a zero‐filled array of length = num_classes\nnum_classes = len(unique_labels)\nsamples_per_class = np.zeros((num_classes,), dtype=np.int32)\n\n# 4) Loop over train_df[\"label\"] and increment the corresponding index\nfor lbl in train_df[\"label\"]:\n    idx = label_to_index[lbl]  \n    samples_per_class[idx] += 1\n\nsamples_per_class","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef make_class_balanced_focal_loss(\n    samples_per_class: np.ndarray,\n    beta: float = 0.99,\n    gamma: float = 1.5\n):\n    \"\"\"\n    Returns a function `cb_focal_loss(y_true, y_pred)` implementing\n    Class‐Balanced Focal Loss for categorical (one‐hot) labels.\n\n    Args:\n      samples_per_class: 1D numpy array of length = num_classes,\n                         where samples_per_class[c] is the number of training samples in class c.\n      beta:             float in [0, 1). Typical values: 0.9 – 0.9999.\n      gamma:            focal‐loss focusing parameter. Typical: 1.0 – 2.0.\n\n    The per‐class weight is computed as:\n        w_c = (1 − beta) / (1 − beta^n_c),\n    then optionally normalized so that sum(w_c) = num_classes.\n    The loss for each sample of true class c is:\n        w_c * (1 − p_t)^gamma * (−log p_t),\n    where p_t = predicted probability for the true class.\n    \"\"\"\n\n    num_classes = int(samples_per_class.shape[0])\n\n    # 1) Compute the class‐balanced weights: w_c = (1 - beta) / (1 - beta^n_c)\n    effective_num = 1.0 - np.power(beta, samples_per_class.astype(np.float32))       # shape=(num_classes,)\n    class_weights = (1.0 - beta) / (effective_num + K.epsilon())                    # avoid division by zero if n_c=0\n\n    # 2) (Optional) Renormalize so that sum(class_weights) = num_classes\n    class_weights = class_weights / np.sum(class_weights) * num_classes\n\n    # 3) Convert to a TF tensor so we can index into it inside the loss\n    class_weights_tf = tf.constant(class_weights, dtype=tf.float32)  # shape=(num_classes,)\n\n    def cb_focal_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n        \"\"\"\n        y_true: one‐hot tensor of shape (batch_size, num_classes)\n        y_pred: probability tensor (after softmax) of shape (batch_size, num_classes)\n        \"\"\"\n        # a) Clip y_pred to avoid log(0)\n        y_pred_clipped = tf.clip_by_value(y_pred, K.epsilon(), 1.0 - K.epsilon())\n\n        # b) Compute p_t = sum_over_c( y_true[c] * y_pred_clipped[c] ) for each sample\n        #    Because y_true is one‐hot, p_t is just the probability assigned to the true class.\n        p_t = tf.reduce_sum(y_true * y_pred_clipped, axis=-1)  # shape=(batch_size,)\n\n        # c) Focal scaling factor: (1 - p_t)^gamma\n        focal_factor = tf.pow(1.0 - p_t, gamma)                # shape=(batch_size,)\n\n        # d) -log(p_t)\n        log_p_t = -tf.math.log(p_t)                            # shape=(batch_size,)\n\n        # e) Gather the class‐balanced weight w_c for each sample:\n        #    weights_for_sample[i] = class_weights_tf[c] if sample i's true class = c\n        weights_for_sample = tf.reduce_sum(class_weights_tf * y_true, axis=-1)  # shape=(batch_size,)\n\n        # f) Compute per‐sample loss:\n        #    loss_i = w_c * (1 - p_t)^gamma * (-log p_t)\n        loss_per_sample = weights_for_sample * focal_factor * log_p_t          # shape=(batch_size,)\n\n        # g) Return the mean over the batch\n        return tf.reduce_mean(loss_per_sample)\n\n    return cb_focal_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"beta  = 0.99   # try 0.99 or 0.999\ngamma = 1.5    # try between 1.0 and 2.0\ncb_focal_loss_fn = make_class_balanced_focal_loss(\n    samples_per_class = samples_per_class,\n    beta               = beta,\n    gamma              = gamma\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_phase3d(seed: int):\n    # (a) Set random seeds so each split is reproducible\n    set_random_seeds(seed)\n\n    # (b) Shuffle the training dataset if you haven’t already\n    # train_shuffled = train_ds.shuffle(buffer_size=2000, seed=seed)\n\n    # (c) Build & unfreeze top-20 layers of Xception (Phase 3-A)\n    model = build_and_unfreeze_xception(n_unfreeze=20)\n\n    # (d) Compile with Adam + CB-Focal Loss (remove class_weight here)\n    optimizer = Adam(learning_rate=1e-4)\n    model.compile(\n        optimizer = optimizer,\n        loss      = cb_focal_loss_fn,       # <— use our custom Class-Balanced Focal Loss\n        metrics   = [\"accuracy\"]    # you can still track accuracy, but monitor macro-F1 separately\n    )\n\n    # (e) Set up callbacks (checkpoint & early stopping)\n    ckpt_path = f\"/kaggle/working/fine_tuned_xcep_cb_loss_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath          = ckpt_path,\n        monitor           = \"val_loss\",   # or ideally \"val_macro_f1\" if you add that callback\n        mode              = \"min\",\n        save_best_only    = True,\n        save_weights_only = True,\n        verbose           = 1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor          = \"val_loss\",    # again, better to track \"val_macro_f1\" if you have it\n        mode             = \"min\",\n        patience         = 7,\n        restore_best_weights = True,\n        verbose          = 1\n    )\n\n    # (f) Fit for up to 50 epochs (no class_weight argument)\n    history = model.fit(\n        train_generator,            # ← YOUR CODE: generator/Dataset built from train_df\n        validation_data = val_generator,  # ← YOUR CODE: generator/Dataset built from val_df\n        epochs          = 50,\n        callbacks       = [checkpoint_cb, earlystop_cb],\n        verbose         = 1\n    )\n\n    # (g) Load best weights (according to lowest val_loss or best val_macro_f1)\n    model.load_weights(ckpt_path)\n\n    # (h) Compute validation macro-F₁ (since loss/accuracy alone is not enough)\n    y_true = []\n    y_pred = []\n    for imgs, labs in val_ds:      # ← YOUR CODE: val_ds yields (image_batch, one_hot_labels)\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"\\nSeed {seed} → Phase 3-D val macro-F₁ = {val_macro_f1:.4f}\\n\")\n\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nphase3d_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Phase 3-D (LLRD) training with seed {seed} ===\")\n    score = train_phase3d(seed)\n    phase3d_scores.append(score)\n\nmean_f1 = np.mean(phase3d_scores)\nstd_f1  = np.std(phase3d_scores)\nprint(f\"\\n→ Phase 3-D (LLRD) val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/fine_tuned_xcep_cb_loss_seed999.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 3E","metadata":{}},{"cell_type":"code","source":"def make_cosine_warmup_scheduler(base_lr: float, total_epochs: int, warmup_epochs: int):\n    def lr_schedule(epoch):\n        if epoch < warmup_epochs:\n            return base_lr * (epoch + 1) / warmup_epochs\n        progress = float(epoch - warmup_epochs) / float(max(1, total_epochs - warmup_epochs))\n        return 0.5 * base_lr * (1.0 + math.cos(math.pi * progress))\n    return LearningRateScheduler(lr_schedule, verbose=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_phase3e(seed: int):\n    set_random_seeds(seed)\n\n    # 1) Build & unfreeze top‐20 layers of Xception\n    model = build_and_unfreeze_xception(n_unfreeze=20)\n\n    # 2) Compute samples_per_class from train_df (as you already did)\n    #    … assume `samples_per_class` is ready …\n\n    # 3) Instantiate CB‐Focal loss\n    beta  = 0.99\n    gamma = 1.5\n    # cb_focal_loss_fn = make_class_balanced_focal_loss(samples_per_class, beta=beta, gamma=gamma)\n\n    # 4) Choose LR parameters for 3E:\n    base_lr = 1e-4\n    total_epochs = 50\n    warmup_epochs = 3\n    cosine_warmup_cb = make_cosine_warmup_scheduler(base_lr, total_epochs, warmup_epochs)\n\n    # 5) Compile the model with base_lr (it will be overridden per‐epoch by our callback)\n    optimizer = Adam(learning_rate=base_lr)\n    model.compile(\n        optimizer = optimizer,\n        loss      = \"categorical_crossentropy\",\n        metrics   = [\"accuracy\"]\n    )\n\n    # 6) Callbacks: checkpoint, early stop, plus our Cosine+Warm-Up schedule\n    ckpt_path = f\"/kaggle/working/fine_tuned_xcep_cosine_seed{seed}.weights.h5\"\n    checkpoint_cb = ModelCheckpoint(\n        filepath          = ckpt_path,\n        monitor           = \"val_loss\",  \n        mode              = \"min\",\n        save_best_only    = True,\n        save_weights_only = True,\n        verbose           = 1\n    )\n    earlystop_cb = EarlyStopping(\n        monitor             = \"val_loss\",  \n        mode                = \"min\",\n        patience            = 7,\n        restore_best_weights= True,\n        verbose             = 1\n    )\n\n    # 7) Fit for 50 epochs (with Cosine+Warm-Up)\n    history = model.fit(\n        train_generator,            # your generator built from train_df\n        validation_data = val_generator,\n        epochs          = total_epochs,\n        callbacks       = [cosine_warmup_cb, checkpoint_cb, earlystop_cb],\n        verbose         = 1,\n        class_weight    = class_weights,\n    )\n\n    # 8) Load best weights & compute val_macro-F1 (as before)\n    model.load_weights(ckpt_path)\n    y_true, y_pred = [], []\n    for imgs, labs in val_ds:\n        probs = model.predict(imgs, verbose=0)\n        y_pred.extend(np.argmax(probs, axis=1))\n        y_true.extend(np.argmax(labs.numpy(), axis=1))\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    val_macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n    print(f\"\\nSeed {seed} → Phase 3-A (with 3E) val macro-F1 = {val_macro_f1:.4f}\\n\")\n    return val_macro_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seeds = [42, 2022, 999]\nphase3e_scores = []\n\nfor seed in seeds:\n    print(f\"\\n=== Phase 3-E Cosine training with seed {seed} ===\")\n    score = train_phase3e(seed)\n    phase3e_scores.append(score)\n\nmean_f1 = np.mean(phase3e_scores)\nstd_f1  = np.std(phase3e_scores)\nprint(f\"\\n→ Phase 3-E Cosine val macro-F₁ over seeds {seeds}: \"\n      f\"{mean_f1:.4f} ± {std_f1:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/fine_tuned_xcep_cosine_seed42.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SWA(tf.keras.callbacks.Callback):\n    \"\"\"\n    Implements Stochastic Weight Averaging (SWA) without using TensorFlow Addons.\n    - start_epoch: 0-based epoch index at which to begin averaging.\n    - verbose: if True, prints updates when averaging begins and ends.\n    \"\"\"\n    def __init__(self, start_epoch=10, verbose=False):\n        super().__init__()\n        self.start_epoch = start_epoch\n        self.verbose = verbose\n        self.swa_n = 0\n        self.swa_weights = None\n\n    def on_epoch_end(self, epoch, logs=None):\n        # Only start averaging once we reach start_epoch (inclusive)\n        if epoch < self.start_epoch:\n            return\n\n        weights = self.model.get_weights()  # list of numpy arrays\n        if self.swa_weights is None:\n            # First time: initialize SWA weights to current model weights\n            self.swa_weights = [w.astype(np.float32) for w in weights]\n            self.swa_n = 1\n            if self.verbose:\n                print(f\"\\n[SWA] Initialized averaging at epoch {epoch}.\")\n        else:\n            # Update running average: new_avg = (prev_avg * n + current) / (n + 1)\n            n = self.swa_n\n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * n + weights[i]) / (n + 1)\n            self.swa_n += 1\n\n    def on_train_end(self, logs=None):\n        # At the end of training, replace model weights with the SWA average\n        if self.swa_weights is not None:\n            if self.verbose:\n                print(f\"\\n[SWA] Assigning averaged weights (over {self.swa_n} snapshots).\")\n            self.model.set_weights(self.swa_weights)\n        else:\n            if self.verbose:\n                print(\"\\n[SWA] No averaging was performed (start_epoch too large).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_and_unfreeze_xception(n_unfreeze=20)\n\nbase_lr = 1e-5\noptimizer = Adam(learning_rate=base_lr)\nmodel.compile(\n    optimizer = optimizer,\n    loss      = \"categorical_crossentropy\",\n    metrics   = [\"accuracy\"]\n)\n\n\nckpt_path = \"/kaggle/working/fine_tuned_xcep_swa_ce.weights.h5\"\ncheckpoint_cb = ModelCheckpoint(\n    filepath          = ckpt_path,\n    monitor           = \"val_loss\",\n    mode              = \"min\",\n    save_best_only    = True,\n    save_weights_only = True,\n    verbose           = 1\n)\nearlystop_cb = EarlyStopping(\n    monitor             = \"val_loss\",\n    mode                = \"min\",\n    patience            = 7,\n    restore_best_weights= True,\n    verbose             = 1\n)\nswa_cb = SWA(start_epoch=5, verbose=True)\n\n\nhistory = model.fit(\n    train_generator,            # your training generator / tf.data.Dataset\n    validation_data = val_generator,\n    epochs          = 50,\n    callbacks       = [checkpoint_cb, earlystop_cb, swa_cb],\n    verbose         = 1,\n    class_weight    = class_weights\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_frozen_xception_model(num_classes)\nmodel.load_weights(\"/kaggle/working/fine_tuned_xcep_swa_ce.weights.h5\")\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\ntest_loss, test_acc = model.evaluate(test_generator, verbose=1)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n\n# Reset the generator’s index to zero, so predictions match filenames:\ntest_generator.reset()\n\n# Number of steps to cover the entire test set\nsteps = int(np.ceil(test_generator.samples / test_generator.batch_size))\n\n# Get softmax predictions for all test images\npred_probs = model.predict(test_generator, steps=steps, verbose=1)\npred_labels = np.argmax(pred_probs, axis=1)\ntrue_labels = test_generator.classes  # integer labels in the same order\n\n# Map indices back to class names\nidx_to_class = {v: k for k, v in test_generator.class_indices.items()}\npred_names = [idx_to_class[i] for i in pred_labels]\ntrue_names = [idx_to_class[i] for i in true_labels]\n\n# Print a quick classification report\nprint(classification_report(true_names, pred_names, digits=4))\n\n# Optionally plot a confusion matrix\n\n\ncm = confusion_matrix(true_labels, pred_labels, labels=list(idx_to_class.keys()))\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt=\"d\",\n    xticklabels=list(idx_to_class.values()),\n    yticklabels=list(idx_to_class.values()),\n    cmap=\"Blues\"\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test-Set Confusion Matrix\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GradCAM","metadata":{}},{"cell_type":"code","source":"model = build_and_unfreeze_xception(\n        n_unfreeze=20\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\n\ndef compute_gradcam(model, img_tensor, class_index=None, layer_name=None):\n    # Find last Conv2D layer if none provided\n    if layer_name is None:\n        for l in reversed(model.layers):\n            if isinstance(l, tf.keras.layers.Conv2D):\n                layer_name = l.name\n                break\n\n    # Create a model that outputs both conv layer activations and predictions\n    grad_model = tf.keras.models.Model(\n        inputs=model.inputs,\n        outputs=[model.get_layer(layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, preds = grad_model(img_tensor)   # conv_outputs: (1, Hc, Wc, C)\n        if class_index is None:\n            class_index = tf.argmax(preds[0])\n        loss = preds[:, class_index]                  # loss: (1,)\n\n    # Compute gradients of the target class score w.r.t. conv feature maps\n    grads = tape.gradient(loss, conv_outputs)         # grads: (1, Hc, Wc, C)\n    pooled_grads = tf.reduce_mean(grads, axis=(1, 2)) # pooled_grads: (1, C)\n\n    conv_outputs = conv_outputs[0]   # (Hc, Wc, C)\n    weights = pooled_grads[0]       # (C,)\n\n    # Multiply each feature map by its corresponding weight (broadcasting)\n    weighted_maps = conv_outputs * weights            # (Hc, Wc, C)\n\n    # Sum across channels to get the raw heatmap, then apply ReLU\n    heatmap = tf.reduce_sum(weighted_maps, axis=-1).numpy()  # (Hc, Wc)\n    heatmap = np.maximum(heatmap, 0)\n\n    # Normalize heatmap to [0, 1]\n    if heatmap.max() != 0:\n        heatmap /= heatmap.max()\n\n    # Resize heatmap to match the input size (H, W)\n    heatmap = cv2.resize(heatmap, (img_tensor.shape[2], img_tensor.shape[1]))\n    return heatmap, preds[0].numpy()\n\n\n# ─────────────────────────────────────────────────────────────────────────────\n# Assume the following are already defined elsewhere in your code:\n#   • model                  → your trained Keras model\n#   • test_generator         → a DirectoryIterator or similar with .filepaths & .class_indices\n#   • (Optional) last_conv   → name of the last Conv2D layer, e.g. \"block14_sepconv2_act\"\n#\n# If you don’t know the layer name in advance, the code below finds it automatically:\n# ─────────────────────────────────────────────────────────────────────────────\nlast_conv = None\nfor layer in reversed(model.layers):\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        last_conv = layer.name\n        break\n\n# Build inverse mapping index → label\nclass_indices_inv = {v: k for k, v in test_generator.class_indices.items()}\n\n# Pick 10 random images from the test set\nnum_samples = len(test_generator.filepaths)\nrandom_idxs = np.random.choice(num_samples, size=10, replace=False)\n\nfor idx in random_idxs:\n    # Load and resize raw image to (224, 224)\n    path = test_generator.filepaths[idx]\n    raw_pil = image.load_img(path, target_size=(224, 224))\n    raw_np  = image.img_to_array(raw_pil).astype(\"uint8\")  # (224,224,3)\n\n    # Prepare model input: scale to [0,1], add batch dim\n    x = raw_np.astype(\"float32\") / 255.0\n    x = np.expand_dims(x, axis=0)  # (1,224,224,3)\n\n    # Compute Grad-CAM heatmap and predictions\n    heatmap, preds = compute_gradcam(model, x, layer_name=last_conv)\n\n    # Convert heatmap to color and overlay on raw image\n    heatmap_uint8 = np.uint8(255 * heatmap)                        \n    heatmap_color = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)  \n    raw_bgr = cv2.cvtColor(raw_np, cv2.COLOR_RGB2BGR)\n    overlay_bgr = cv2.addWeighted(raw_bgr, 0.6, heatmap_color, 0.4, 0)\n    overlay_rgb = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)\n\n    # Determine predicted label and confidence\n    pred_idx   = np.argmax(preds)\n    pred_label = class_indices_inv[pred_idx]\n    pred_conf  = preds[pred_idx]\n\n    # Plot original and Grad-CAM overlay side by side\n    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n    axes[0].imshow(raw_np.astype(\"uint8\"))\n    axes[0].axis(\"off\")\n    axes[0].set_title(\"Original\")\n    axes[1].imshow(overlay_rgb.astype(\"uint8\"))\n    axes[1].axis(\"off\")\n    axes[1].set_title(f\"{pred_label} ({pred_conf:.3f})\")\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}